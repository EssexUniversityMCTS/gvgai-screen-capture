package controllers.ScreenCaptureAgent;

import java.awt.Color;
import java.awt.image.BufferedImage;
import java.awt.image.DataBufferInt;
import java.awt.image.WritableRaster;
import java.io.File;
import java.io.IOException;
import java.util.ArrayList;
import java.util.Random;

import javax.imageio.ImageIO;
import javax.swing.table.DefaultTableModel;

import ontology.Types;
import ontology.Types.ACTIONS;

import org.deeplearning4j.nn.api.OptimizationAlgorithm;
import org.deeplearning4j.nn.conf.MultiLayerConfiguration;
import org.deeplearning4j.nn.conf.NeuralNetConfiguration;
import org.deeplearning4j.nn.conf.Updater;
import org.deeplearning4j.nn.conf.layers.ConvolutionLayer;
import org.deeplearning4j.nn.conf.layers.DenseLayer;
import org.deeplearning4j.nn.conf.layers.OutputLayer;
import org.deeplearning4j.nn.conf.layers.SubsamplingLayer;
import org.deeplearning4j.nn.conf.layers.setup.ConvolutionLayerSetup;
import org.deeplearning4j.nn.multilayer.MultiLayerNetwork;
import org.deeplearning4j.nn.weights.WeightInit;
import org.nd4j.linalg.api.ndarray.INDArray;
import org.nd4j.linalg.factory.Nd4j;
import org.nd4j.linalg.lossfunctions.LossFunctions;

import tools.ElapsedCpuTimer;
import core.game.Game;
import core.game.StateObservation;
import core.player.AbstractPlayer;

public class Agent extends AbstractPlayer{

	/**
	 * initialize all variables for the agent
	 * @param stateObs Observation of the current state.
     * @param elapsedTimer Timer when the action returned is due.
	 */
	static int poolSize = 200;
	static int batchSize = 20;
	int currentIndex;
	public static Experience[] experiencePool = new Experience[poolSize];
	Random random = new Random();
	MyFrame frame;
	boolean start = false;
	
	MultiLayerNetwork model;
	
	DefaultTableModel tableModel;
	
	private QLearning learning;
	
	public Agent(StateObservation stateObs, ElapsedCpuTimer elapsedTimer){
		learning = new QLearning(experiencePool,stateObs.getAvailableActions().size());
		frame = new MyFrame(experiencePool,stateObs.getAvailableActions(),learning.qValues);
		tableModel = (DefaultTableModel) frame.table.getModel();
		frame.setVisible(true);
		currentIndex = 0;
		 int nChannels = 1;
	     int outputNum = stateObs.getAvailableActions().size();
	     int batchSize = 100;//1000;
	     int nEpochs = 10;
	     int iterations = 1;
	     int seed = 123;
	       
	     
	     for(int i=0;i<poolSize;i++)
	    	 tableModel.addRow(new String[]{});
	     /*   BufferedImage bufferedImage = Game.im;
			
	        while(bufferedImage == null) {
				//	bufferedImage = ImageIO.read(imgPath);
		//			System.out.println("null");
	        	bufferedImage = Game.im;
				//	return null;
			}
	       */ 
	        int blockW = stateObs.getBlockSize();//25;
	       // float[] pixs = preProcess(bufferedImage,blockW);
	        
	    //    System.out.println(bufferedImage.getWidth()+"x"+bufferedImage.getHeight()+"="+pixels.length);
	  
	      //  System.out.println(pixs[2]);
	        int w = Game.width/blockW;//bufferedImage.getWidth()/blockW;
	        int h = Game.width/blockW;//bufferedImage.getHeight()/blockW;
	        
	       // INDArray nd = Nd4j.create(pixs);
   //     log.info("Build model....");
        MultiLayerConfiguration.Builder builder = new NeuralNetConfiguration.Builder()
                .seed(seed)
                .iterations(iterations)
                .regularization(true).l2(0.0005)
                .learningRate(0.01)
                .weightInit(WeightInit.XAVIER)
                .optimizationAlgo(OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT)
                .updater(Updater.NESTEROVS).momentum(0.9)
                .list(2) //layer size
                .layer(0, new ConvolutionLayer.Builder(5, 5) //kernelsize[]
                        .nIn(nChannels) //dimensions?
                        .stride(1, 1) //stride[]
                        .nOut(20) //num output
                        .dropOut(0.5) //rate of droping some units
                        .activation("relu") //rectifier linear
                        .build())
       /*         .layer(1, new SubsamplingLayer.Builder(SubsamplingLayer.PoolingType.MAX)
                        .kernelSize(2,2)
                        .stride(2,2)
                        .build())
                .layer(2, new DenseLayer.Builder().activation("relu")
                        .nOut(500).build())*/
                .layer(1, new OutputLayer.Builder(LossFunctions.LossFunction.NEGATIVELOGLIKELIHOOD)
                        .nOut(outputNum)
                        .activation("softmax")
                        .build())
                .backprop(true).pretrain(false);
        new ConvolutionLayerSetup(builder,w,h,1);

        MultiLayerConfiguration conf = builder.build();
        model = new MultiLayerNetwork(conf);
        model.init();


    //    log.info("Train model....");
   //     model.setListeners(new ScoreIterationListener(1));
    //    for( int i=0; i<nEpochs; i++ ) {
        //	System.out.println("ep "+nEpochs);
        	//System.out.println(nd+""+nd.length());
      //      model.fit(nd);//iterator);//mnistTrain);
            
        //    System.out.println(model.params());
            
   //         log.info("*** Completed epoch {} ***", i);
/*
            log.info("Evaluate model....");
            
            Evaluation eval = new Evaluation(outputNum);
           // while(.hasNext()){
             //   DataSet ds = iterator.next();
                INDArray output = model.output(nd);//ds.getFeatureMatrix());//model.output(ds.getFeatureMatrix());
                eval.eval(nd,output);//ds.getLabels(), output);
           // }
            log.info(eval.stats());
       //     iterator.reset();//mnistTest.reset();
            
        
        }
        
        log.info("****************Example finished********************");
*/
		
	}
	
	/**
	 * return ACTION_NIL on every call to simulate doNothing player
	 * @param stateObs Observation of the current state.
     * @param elapsedTimer Timer when the action returned is due.
	 * @return 	ACTION_NIL all the time
	 */
	
	Experience experience;
	public ACTIONS act(StateObservation stateObs, ElapsedCpuTimer elapsedTimer) {
		
       
       // log.info("Load data....");
      //  DataSetIterator mnistTrain = new MnistDataSetIterator(batchSize,true,12345);
        
       // DataSetIterator mnistTest = new MnistDataSetIterator(batchSize,false,12345);

      //  File imgPath = new File("screenshots/2_2.0.png");//_shrink.png");
        BufferedImage bufferedImage = Game.im;
		
        if(bufferedImage == null) {
			//	bufferedImage = ImageIO.read(imgPath);
	//			System.out.println("null");
				return Types.ACTIONS.ACTION_NIL;
		}
        else Game.im = null;
        
        int blockW = stateObs.getBlockSize();//25;
        double[][] pixs = preProcess(bufferedImage,blockW);
        
        if(experience == null)
        {
        	experience = new Experience();
        	experience.setPrevious(pixs);
        }
        
        else
        {
        	experience.setResult(pixs);
        	experience.setReward(stateObs.getGameScore());

        	tableModel.setValueAt("experience "+currentIndex,currentIndex,0);
        	//learning.mapper.put(experience.copy(), currentIndex);
        	learning.qValues[currentIndex] = new double[stateObs.getAvailableActions().size()];
        	experiencePool[currentIndex++] = experience.copy();
        	
        	if(currentIndex == poolSize)
        	{
        		currentIndex = 0;
        	}
        	
        	experience = new Experience();
        	experience.setPrevious(pixs);
        }
        
        //double[][] p = new double[0][0];
    //    System.out.println(bufferedImage.getWidth()+"x"+bufferedImage.getHeight()+"="+pixels.length);
  
      //  System.out.println(pixs[2]);
       // INDArray nd = Nd4j.create(pixs);
       // model.fit(nd);
         //     for(int i=0;i<nd.length();i++)
//        	System.out.println(nd); 
		//System.out.println(model.params());
        
        ArrayList<Types.ACTIONS> actions = stateObs.getAvailableActions();
        
        int index = learning.getMaxActionIndexFromScreenCap(pixs);
        		if(index==-1)
        			index = random.nextInt(actions.size());
        
        if(!start && currentIndex>batchSize)
        {
        	start = true;
        }
        
        if(start)
        for(int i=0;i<batchSize;i++)
        {
        	int rand = 0;
        	do
        	{
        		rand = random.nextInt(poolSize);
        	}while(experiencePool[rand]==null);
        	
        	Experience toUpdateExp = experiencePool[rand];
        	learning.qUpdate(rand, actions.indexOf(toUpdateExp.getAction()),toUpdateExp.getReward());
        }
        //     System.out.println(index);
        
        experience.setAction(actions.get(index));
        
		return actions.get(index);
	}
	
	@Override
	public void result(StateObservation stateObservation, ElapsedCpuTimer elapsedCpuTimer)
    {
		System.out.println("WIN = "+stateObservation.getGameWinner().equals(Types.WINNER.PLAYER_WINS));
		
		if(stateObservation.getGameWinner().equals(Types.WINNER.PLAYER_WINS))
		{
			experience.setReward(experience.getReward()+1000);
		}
		else
		{
			experience.setReward(experience.getReward()-1000);
		}
		experience.setResult(null);
		tableModel.setValueAt("experience "+currentIndex,currentIndex,0);
    	//learning.mapper.put(experience.copy(), currentIndex);
    	learning.qValues[currentIndex] = new double[stateObservation.getAvailableActions().size()];
    	experiencePool[currentIndex++] = experience.copy();
    	
    	if(currentIndex == poolSize)
    	{
    		currentIndex = 0;
    	}
    	
    
    }
	
//	private static final Logger log = LoggerFactory.getLogger(Agent.class);
	private static int[][] convertTo2DWithoutUsingGetRGB(BufferedImage image) {

		if(image==null)
			return null;
	/*	  int [] pix =  ((DataBufferInt) image.getRaster().getDataBuffer()).getData();
		  
		  ByteBuffer byteBuffer = ByteBuffer.allocate(pix.length * 4);        
	      IntBuffer intBuffer = byteBuffer.asIntBuffer();
	      intBuffer.put(pix);

	      final byte[] pixels = byteBuffer.array();
	     */
	      final int width = image.getWidth();
	      final int height = image.getHeight();
	    //  System.out.println("2D "+width+" "+height);
	      int[][] result = new int[width][height];
	      
	      for(int i=0;i<width;i++)
	    	  for(int j=0;j<height;j++)
	    	  {
	    		 // System.out.println(width+" "+height+" "+i+" "+j);
	    		  result[i][j] = image.getRGB(i, j);
	    	  }
	      
	      
	/*      final boolean hasAlphaChannel = image.getAlphaRaster() != null;

	      int[][] result = new int[height][width];
	      if (hasAlphaChannel) {
	         final int pixelLength = 4;
	         for (int pixel = 0, row = 0, col = 0; pixel < pixels.length; pixel += pixelLength) {
	            int argb = 0;
	            argb += (((int) pixels[pixel] & 0xff) << 24); // alpha
	            argb += ((int) pixels[pixel + 1] & 0xff); // blue
	            argb += (((int) pixels[pixel + 2] & 0xff) << 8); // green
	            argb += (((int) pixels[pixel + 3] & 0xff) << 16); // red
	            result[row][col] = argb;
	            col++;
	            if (col == width) {
	               col = 0;
	               row++;
	            }
	         }
	      } else {
	         final int pixelLength = 3;
	         for (int pixel = 0, row = 0, col = 0; pixel < pixels.length; pixel += pixelLength) {
	            int argb = 0;
	            argb += -16777216; // 255 alpha
	            argb += ((int) pixels[pixel] & 0xff); // blue
	            argb += (((int) pixels[pixel + 1] & 0xff) << 8); // green
	            argb += (((int) pixels[pixel + 2] & 0xff) << 16); // red
	            result[row][col] = argb;
	            col++;
	            if (col == width) {
	               col = 0;
	               row++;
	            }
	         }
	      }
*/
	      return result;
	   }

	public static double[][] preProcess(BufferedImage image, int block)
	{
		int[][] im = convertTo2DWithoutUsingGetRGB(image);
		if(im == null)
			return null;
		//System.out.println(im.length+" "+im[0].length);
	/*	BufferedImage nm = new BufferedImage(im.length,im[0].length,BufferedImage.TYPE_INT_RGB);
		for(int i=0;i<im.length;i++)
			for(int j=0;j<im[0].length;j++)
			{
				nm.setRGB(i,j,im[i][j]);
			}
		BufferedImage temp = new BufferedImage(im.length,im[0].length,BufferedImage.TYPE_INT_RGB);
		for(int i=0;i<im.length;i++)
			for(int j=0;j<im[0].length;j++)
				temp.setRGB(i,j,im[i][j]);
		File op = new File("pre.png");
	    try {
			ImageIO.write(temp, "png", op);
		} catch (IOException e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		}
		*/
		
		int width = image.getWidth();
		int height = image.getHeight();
		
		int res = width*height;
		
		double[][] shrinkedIm = new double[width/block][height/block];
		
	//	System.out.println(im.length+" "+im[0].length);
	//	System.out.println(shrinkedIm.length+" "+shrinkedIm[0].length);
		
		
		for(int i=0;i<width/block;i++)
		{
			for(int j=0;j<height/block;j++)
			{
				//System.out.println(i+"\t"+j);
				int startW = i*block;
				int endW = startW+(block-1);
				int startH = j*block;
				int endH = startH+(block-1);
				
	//			System.out.println(i+"\t"+j+"\t"+startW+"\t"+endW+"\t"+startH+"\t"+endH);
				
				int mean[] = new int[3];//Integer.MIN_VALUE;
				
				for(int k=startW;k<=endW;k++)
					for(int m=startH;m<=endH;m++)
					{
						Color c = new Color(im[k][m]);
						int red = c.getRed();
						int green = c.getGreen();
						int blue = c.getBlue();
							
						//if(im[k][m]>mean)
						//mean+=im[k][m];
						mean[0] += red;
						mean[1] += green;
						mean[2] += blue;
					}
				
				mean[0]/= block*block;
				mean[1]/= block*block;
				mean[2]/= block*block;
				
				shrinkedIm[i][j] = mean[0]*65536+mean[1]*256+mean[2];
			}
		}
		/*
		for(int i=0;i<shrinkedIm.length;i++)
		{
			for(int j=0;j<shrinkedIm[0].length;j++)
				System.out.print(shrinkedIm[i][j]+",");
			System.out.println();
		}
		*/
		/*
		BufferedImage newImage = new BufferedImage(shrinkedIm.length,shrinkedIm[0].length,BufferedImage.TYPE_INT_RGB);
		
		for(int i=0;i<shrinkedIm.length;i++)
			for(int j=0;j<shrinkedIm[0].length;j++)
			{
				newImage.setRGB(i,j,shrinkedIm[i][j]);
			}
	
		File outputfile = new File("nm_"+block+".png");
	    try {
			ImageIO.write(newImage, "png", outputfile);
		} catch (IOException e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		}
	    
        // get DataBufferBytes from Raster
        WritableRaster raster = newImage .getRaster();
        DataBufferInt data   = (DataBufferInt) raster.getDataBuffer();
        
        int[] pixels = data.getData();
        float[] pixs = new float[pixels.length];
        
        for(int i=0;i<pixs.length;i++)
        	pixs[i] = pixels[i];
		*/
		return shrinkedIm;
		
	}

}
